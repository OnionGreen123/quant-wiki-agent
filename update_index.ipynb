{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 更新基本概念时的流程：\n",
    "- 翻译文章\n",
    "- 将文章分类放进对应的文件夹下面（llm进行分类）\n",
    "- 更新知识框架部分\n",
    "- 将文章进一步分类，更新mkdocs.yml\n",
    "- 根据分类结果更新概述"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 翻译所用的脚本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import argparse\n",
    "import threading\n",
    "import concurrent.futures\n",
    "import re\n",
    "import requests\n",
    "import time\n",
    "import random\n",
    "from typing import List, Dict, Any, Tuple, Callable\n",
    "\n",
    "class MarkdownTranslator:\n",
    "    def __init__(self, api_key: str, base_url: str, model: str, max_tokens: int = 4000, max_retries: int = 3):\n",
    "        self.api_key = api_key\n",
    "        self.base_url = base_url\n",
    "        self.model = model\n",
    "        self.max_tokens = max_tokens\n",
    "        self.max_retries = max_retries\n",
    "        self.lock = threading.Lock()\n",
    "        \n",
    "    def _retry_with_backoff(self, func: Callable, *args, **kwargs) -> Any:\n",
    "        \"\"\"使用指数退避策略重试函数调用\"\"\"\n",
    "        retry_count = 0\n",
    "        while retry_count <= self.max_retries:\n",
    "            try:\n",
    "                return func(*args, **kwargs)\n",
    "            except Exception as e:\n",
    "                retry_count += 1\n",
    "                if retry_count > self.max_retries:\n",
    "                    # 已达到最大重试次数，重新抛出异常\n",
    "                    raise e\n",
    "                \n",
    "                # 计算退避时间（指数增长，有随机抖动）\n",
    "                backoff_time = min(2 ** (retry_count - 1), 60) + random.uniform(0, 1)\n",
    "                \n",
    "                with self.lock:\n",
    "                    print(f\"API调用失败: {str(e)}. 将在 {backoff_time:.2f} 秒后进行第 {retry_count}/{self.max_retries} 次重试...\")\n",
    "                \n",
    "                time.sleep(backoff_time)\n",
    "        \n",
    "        # 这里不应该执行到，但为了逻辑完整性添加\n",
    "        raise Exception(\"所有重试尝试均失败\")\n",
    "        \n",
    "    def _translate_text_impl(self, text: str) -> str:\n",
    "        \"\"\"实际执行翻译的内部函数\"\"\"\n",
    "        headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Authorization\": f\"Bearer {self.api_key}\"\n",
    "        }\n",
    "        \n",
    "        payload = {\n",
    "            \"model\": self.model,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"你是一个专业的翻译助手，请将以下Markdown文本翻译成流畅、自然的中文，保留原始的Markdown格式和标记。代码块内容不需要翻译，引用文献部分也不需要翻译\"},\n",
    "                {\"role\": \"user\", \"content\": text}\n",
    "            ],\n",
    "            \"temperature\": 0.3\n",
    "        }\n",
    "        \n",
    "        response = requests.post(f\"{self.base_url}/v1/chat/completions\", \n",
    "                                headers=headers, \n",
    "                                json=payload,\n",
    "                                timeout=60)\n",
    "        response.raise_for_status()\n",
    "        result = response.json()\n",
    "        return result[\"choices\"][0][\"message\"][\"content\"]\n",
    "        \n",
    "    def translate_text(self, text: str) -> str:\n",
    "        \"\"\"调用LLM API翻译文本（带重试功能）\"\"\"\n",
    "        try:\n",
    "            return self._retry_with_backoff(self._translate_text_impl, text)\n",
    "        except Exception as e:\n",
    "            print(f\"翻译文本最终失败: {str(e)}\")\n",
    "            return text  # 所有重试都失败时返回原文本\n",
    "    \n",
    "    def split_text(self, text: str) -> List[str]:\n",
    "        \"\"\"将长文本分割成不超过最大token数的片段\"\"\"\n",
    "        # 使用简单的估算方法：1个中文字符约1.5个token，1个英文单词约1.3个token\n",
    "        # 这只是一个粗略估计，实际token数会有所不同\n",
    "        \n",
    "        # 先保护代码块\n",
    "        code_blocks = []\n",
    "        \n",
    "        def replace_code_blocks(match):\n",
    "            code_blocks.append(match.group(0))\n",
    "            return f\"__CODE_BLOCK_{len(code_blocks)-1}__\"\n",
    "        \n",
    "        # 使用正则表达式匹配代码块\n",
    "        code_block_pattern = r\"```[\\s\\S]*?```\"\n",
    "        text_with_placeholders = re.sub(code_block_pattern, replace_code_blocks, text)\n",
    "        \n",
    "        # 按段落分割文本\n",
    "        paragraphs = re.split(r'\\n\\s*\\n', text_with_placeholders)\n",
    "        \n",
    "        # 重新组合段落，确保每个片段不超过最大token数\n",
    "        chunks = []\n",
    "        current_chunk = \"\"\n",
    "        current_tokens = 0\n",
    "        \n",
    "        for para in paragraphs:\n",
    "            # 估算段落的token数\n",
    "            estimated_tokens = len(para.split()) * 1.3 + len(re.findall(r'[\\u4e00-\\u9fff]', para)) * 1.5\n",
    "            \n",
    "            if current_tokens + estimated_tokens > self.max_tokens * 0.8:  # 留出20%的余量\n",
    "                if current_chunk:\n",
    "                    chunks.append(current_chunk)\n",
    "                current_chunk = para\n",
    "                current_tokens = estimated_tokens\n",
    "            else:\n",
    "                if current_chunk:\n",
    "                    current_chunk += \"\\n\\n\" + para\n",
    "                else:\n",
    "                    current_chunk = para\n",
    "                current_tokens += estimated_tokens\n",
    "        \n",
    "        if current_chunk:\n",
    "            chunks.append(current_chunk)\n",
    "            \n",
    "        # 还原代码块\n",
    "        final_chunks = []\n",
    "        for chunk in chunks:\n",
    "            for i, code_block in enumerate(code_blocks):\n",
    "                chunk = chunk.replace(f\"__CODE_BLOCK_{i}__\", code_block)\n",
    "            final_chunks.append(chunk)\n",
    "            \n",
    "        return final_chunks\n",
    "    \n",
    "    def _translate_filename_impl(self, filename: str) -> str:\n",
    "        \"\"\"实际执行文件名翻译的内部函数\"\"\"\n",
    "        # 分离文件名和扩展名\n",
    "        name, ext = os.path.splitext(filename)\n",
    "        \n",
    "        # 如果文件名看起来已经是中文，就不翻译了\n",
    "        if re.search(r'[\\u4e00-\\u9fff]', name):\n",
    "            return filename\n",
    "        \n",
    "        headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Authorization\": f\"Bearer {self.api_key}\"\n",
    "        }\n",
    "        \n",
    "        payload = {\n",
    "            \"model\": self.model,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"请将以下英文文件名（金融或经济领域）翻译成简短、清晰的中文。并以中文名_英文名的格式返回。只翻译内容含义，不要添加额外词语，保持简洁。\"},\n",
    "                {\"role\": \"user\", \"content\": name}\n",
    "            ],\n",
    "            \"temperature\": 0.3\n",
    "        }\n",
    "        \n",
    "        response = requests.post(f\"{self.base_url}/v1/chat/completions\", \n",
    "                                headers=headers, \n",
    "                                json=payload,\n",
    "                                timeout=30)\n",
    "        response.raise_for_status()\n",
    "        result = response.json()\n",
    "        translated_name = result[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "        \n",
    "        # 确保翻译后的文件名是有效的\n",
    "        translated_name = re.sub(r'[\\\\/*?:\"<>|]', '', translated_name)  # 移除Windows文件名中不允许的字符\n",
    "        \n",
    "        return translated_name + ext\n",
    "    \n",
    "    def translate_filename(self, filename: str) -> str:\n",
    "        \"\"\"翻译文件名为中文（带重试功能）\"\"\"\n",
    "        try:\n",
    "            return self._retry_with_backoff(self._translate_filename_impl, filename)\n",
    "        except Exception as e:\n",
    "            print(f\"文件名翻译最终失败: {str(e)}\")\n",
    "            return filename  # 所有重试都失败时返回原文件名\n",
    "    \n",
    "    def translate_file(self, file_path: str, output_dir: str = None) -> None:\n",
    "        \"\"\"翻译单个文件\"\"\"\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "                \n",
    "            # 分割文本\n",
    "            chunks = self.split_text(content)\n",
    "            \n",
    "            # 翻译每个片段\n",
    "            translated_chunks = []\n",
    "            for i, chunk in enumerate(chunks):\n",
    "                with self.lock:\n",
    "                    print(f\"正在翻译 {file_path} 的第 {i+1}/{len(chunks)} 部分...\")\n",
    "                translated_chunk = self.translate_text(chunk)\n",
    "                translated_chunks.append(translated_chunk)\n",
    "                \n",
    "            # 合并翻译后的文本\n",
    "            translated_content = \"\\n\\n\".join(translated_chunks)\n",
    "            \n",
    "            # 翻译并确定输出路径\n",
    "            file_name = os.path.basename(file_path)\n",
    "            translated_file_name = self.translate_filename(file_name)\n",
    "            \n",
    "            if output_dir:\n",
    "                if not os.path.exists(output_dir):\n",
    "                    os.makedirs(output_dir)\n",
    "                output_path = os.path.join(output_dir, translated_file_name)\n",
    "            else:\n",
    "                dir_name = os.path.dirname(file_path)\n",
    "                output_path = os.path.join(dir_name, translated_file_name)\n",
    "            \n",
    "            # 写入翻译后的文件\n",
    "            with open(output_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(translated_content)\n",
    "                \n",
    "            with self.lock:\n",
    "                print(f\"✅ 已完成文件翻译: {file_path} -> {output_path}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            with self.lock:\n",
    "                print(f\"❌ 翻译文件失败 {file_path}: {str(e)}\")\n",
    "    \n",
    "    def translate_directory(self, input_dir: str, output_dir: str = None, max_workers: int = 5) -> None:\n",
    "        \"\"\"使用多线程翻译文件夹内所有Markdown文件\"\"\"\n",
    "        # 查找所有markdown文件\n",
    "        md_files = glob.glob(os.path.join(input_dir, \"**\", \"*.md\"), recursive=True)\n",
    "        \n",
    "        if not md_files:\n",
    "            print(f\"在 {input_dir} 中未找到Markdown文件\")\n",
    "            return\n",
    "        \n",
    "        print(f\"发现 {len(md_files)} 个Markdown文件，准备翻译...\")\n",
    "        \n",
    "        # 使用线程池进行多线程翻译\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            futures = [executor.submit(self.translate_file, file_path, output_dir) for file_path in md_files]\n",
    "            \n",
    "            # 等待所有任务完成\n",
    "            concurrent.futures.wait(futures)\n",
    "            \n",
    "        print(f\"所有文件翻译完成！\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"使用大语言模型将Markdown文件翻译成中文\")\n",
    "    parser.add_argument(\"--input_dir\", \"-i\", required=True, help=\"包含Markdown文件的输入目录\")\n",
    "    parser.add_argument(\"--output_dir\", \"-o\", help=\"翻译后文件的输出目录\")\n",
    "    parser.add_argument(\"--api_key\", \"-k\", required=True, help=\"大语言模型API密钥\")\n",
    "    parser.add_argument(\"--base_url\", \"-u\", default=\"https://api.openai.com\", help=\"API基础URL\")\n",
    "    parser.add_argument(\"--model\", \"-m\", default=\"gpt-3.5-turbo\", help=\"使用的模型名称\")\n",
    "    parser.add_argument(\"--max_tokens\", \"-t\", type=int, default=4000, help=\"每个翻译片段的最大token数\")\n",
    "    parser.add_argument(\"--threads\", \"-n\", type=int, default=3, help=\"并行处理的线程数\")\n",
    "    parser.add_argument(\"--retries\", \"-r\", type=int, default=3, help=\"API调用失败时的最大重试次数\")\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    translator = MarkdownTranslator(\n",
    "        api_key=args.api_key,\n",
    "        base_url=args.base_url,\n",
    "        model=args.model,\n",
    "        max_tokens=args.max_tokens,\n",
    "        max_retries=args.retries\n",
    "    )\n",
    "    \n",
    "    translator.translate_directory(\n",
    "        input_dir=args.input_dir,\n",
    "        output_dir=args.output_dir,\n",
    "        max_workers=args.threads\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将文件分类放进对应的文件夹下面（手动）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 更新知识框架部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "def generate_navigation(directory_path):\n",
    "    # 获取指定目录下所有的md文件\n",
    "    md_files = glob.glob(os.path.join(directory_path, \"*.md\"))\n",
    "    \n",
    "    # 生成导航列表\n",
    "    navigation = []\n",
    "    for file_path in md_files:\n",
    "        # 获取文件名（不含扩展名）\n",
    "        file_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "        # 获取相对路径，并移除 ../../../docs/basic/ 前缀\n",
    "        relative_path = os.path.relpath(file_path, \"/Users/fengwenjun/Desktop/CODE/Automatic tools for LLMQuant/quant-wiki/docs/basic\")\n",
    "        # 确保路径使用正斜杠\n",
    "        relative_path = relative_path.replace('\\\\', '/')\n",
    "        # 生成导航项\n",
    "        nav_item = f\"- [{file_name}]({relative_path})\"\n",
    "        navigation.append(nav_item)\n",
    "    \n",
    "    return \"\\n\".join(sorted(navigation))\n",
    "\n",
    "# 使用示例\n",
    "directory_path = \"/Users/fengwenjun/Desktop/CODE/Automatic tools for LLMQuant/quant-wiki/docs/basic/stat\"\n",
    "nav_text = generate_navigation(directory_path)\n",
    "print(nav_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将文章进一步分类，更新mkdocs.yml(使用cursor)\n",
    "先使用git show --name-only a1b2c  打印出文件变更情况\n",
    "使用cursor直接编辑 mkdocs.yml：我更新了很多文件，请你根据此来分类并更新mkdocs中基本概念的部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 根据分类结果更新综述\n",
    "\n",
    "将mkdocs中的内容输入大模型进行转写，用下面的prompt进行转写\n",
    "\n",
    "你是一个文案编辑整理大师，你需要转写用户提供的文本为一个markdown。实例输入：\n",
    "    - 金融术语: \n",
    "      - 市场与交易:\n",
    "        - 一级市场: basic/finance/一级市场_Primary Market.md\n",
    "        - 二级市场: basic/finance/二级市场_Secondary Market.md\n",
    "        - 债券市场: basic/finance/债券市场_Bond Market.md\n",
    "        - 外汇市场: basic/finance/外汇市场_Foreign Exchange.md\n",
    "        - 股市: basic/finance/股市_Stock Market.md\n",
    "        - 熊市: basic/finance/熊市_Bear Market.md\n",
    "        - 牛市: basic/finance/牛市_Bull Market.md\n",
    "        - 纳斯达克: basic/finance/纳斯达克_Nasdaq.md\n",
    "      - 金融工具:\n",
    "        - 股权: basic/finance/股权_Equity.md\n",
    "        - 期货: basic/finance/期货_Futures.md \n",
    "输出：\n",
    "# 金融术语\n",
    "\n",
    "## 章节导航\n",
    "\n",
    "### 市场与交易\n",
    "\n",
    "- [一级市场](一级市场_Primary Market.md)\n",
    "- [二级市场](二级市场_Secondary Market.md)\n",
    "- [债券市场](债券市场_Bond Market.md)\n",
    "- [外汇市场](外汇市场_Foreign Exchange.md)\n",
    "- [股市](股市_Stock Market.md)\n",
    "- [熊市](熊市_Bear Market.md)\n",
    "- [牛市](牛市_Bull Market.md)\n",
    "- [纳斯达克](纳斯达克_Nasdaq.md)\n",
    "\n",
    "### 金融工具\n",
    "\n",
    "- [股权](股权_Equity.md)\n",
    "- [期货](期货_Futures.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantwiki",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
